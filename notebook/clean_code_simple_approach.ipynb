{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def read_data(filename, sample_size=None):\n",
    "    df = pd.read_csv(filename)\n",
    "    if sample_size is not None:\n",
    "        df = df.sample(sample_size)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "    import numpy as np\n",
    "    \n",
    "    y = [] # collect targets\n",
    "    data = [] # data (all columns except the target)\n",
    "\n",
    "    target_col = 'TARGET'\n",
    "    features = list([x for x in train_df.columns if x != target_col])\n",
    "\n",
    "    for row in train_df.to_dict('records'):\n",
    "        y.append(row[target_col])\n",
    "        data.append({k: row[k] for k in features})\n",
    "    \n",
    "    return data, np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, y):\n",
    "    # train-test split\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    data_train, data_val, y_train, y_val = train_test_split(data, y, train_size=0.8, stratify=y)\n",
    "    print(f'data_train: {len(data_train)}')\n",
    "    print(f'data_val: {len(data_val)}')\n",
    "    \n",
    "    return data_train, data_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_data(data_train):\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    from sklearn.preprocessing import MaxAbsScaler\n",
    "    from sklearn.feature_extraction import DictVectorizer\n",
    "      \n",
    "    vectorizer = DictVectorizer()\n",
    "    X_train = vectorizer.fit_transform(data_train)\n",
    "  \n",
    "    # fill in nan values\n",
    "    imputer = Imputer()\n",
    "    X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "    # scaling data by columns so different features have roughly the same magnitude\n",
    "    scaler = MaxAbsScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    \n",
    "    return X_train, (vectorizer, imputer, scaler) # need to reuse these preprocessors on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data(data_test, processors):\n",
    "    X_test = None\n",
    "    for processor in processors:\n",
    "        X_test = processor.transform(X_test if X_test is not None else data_test)\n",
    "        \n",
    "    return X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data_train, data_val, y_train, y_val):\n",
    "    X_train, processors = process_train_data(data_train)\n",
    "    X_val = process_test_data(data_val, processors=processors)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, roc_auc):\n",
    "    import matplotlib.pyplot as plt\n",
    "    lw = 2\n",
    "    plt.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_predict(X_train, X_val, y_train, y_val):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    import time\n",
    "\n",
    "    # fit model\n",
    "    model = LogisticRegression(class_weight='balanced')\n",
    "  \n",
    "    start = time.time()\n",
    "    print(f'Fitting model on {X_train.shape[0]} samples...')\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Finished model training in %.3f seconds.' % (end - start))\n",
    "\n",
    "    # compute area under ROC\n",
    "    # we need probabilities to do this\n",
    "    pos_idx = list(model.classes_).index(1)\n",
    "    y_score = model.predict_proba(X_val)[:, pos_idx]\n",
    "    return y_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/application_train.csv'\n",
    "train_df = read_data(filename=filename, sample_size=10000)\n",
    "train_df.head(20)\n",
    "data, y = transform_data(train_df)\n",
    "data_train, data_val, y_train, y_val = split_data(data, y)    \n",
    "X_train, X_val, y_train, y_val = process_data(data_train, data_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, roc_curve\n",
    "\n",
    "y_score = train_predict(X_train, X_val, y_train, y_val)\n",
    "roc_auc = roc_auc_score(y_val, y_score)\n",
    "fpr, tpr, _ = roc_curve(y_val, y_score, pos_label=1)\n",
    "\n",
    "plot_roc_curve(fpr, tpr, roc_auc)\n",
    "print(f'Area under ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = 'data/application_train.csv'\n",
    "train_df = read_data(filename=train_filename, sample_size=10000)\n",
    "data_train, y_train = transform_data(train_df)\n",
    "X_train, processors = process_train_data(data_train)\n",
    "\n",
    "test_filename = 'data/application_test.csv'\n",
    "test_df = read_data(filename=test_filename)\n",
    "data_test, y_test = transform_data(test_df)\n",
    "X_test = process_test_data(data_test, processors=processors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all sampled data for training\n",
    "# and predict on the test data\n",
    "y_score = train_predict(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for i, y_pred in enumerate(y_score):\n",
    "    predictions.append({'SK_ID_CURR': data_test[i]['SK_ID_CURR'], 'TARGET': y_pred})\n",
    "\n",
    "out_df = pd.DataFrame(data=predictions)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
