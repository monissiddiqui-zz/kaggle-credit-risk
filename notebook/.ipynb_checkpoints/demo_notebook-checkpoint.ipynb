{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://weclouddata.com/wp-content/uploads/2016/11/logo.png' width='30%'>\n",
    "-------------\n",
    "\n",
    "<h3 align='center'> Machine Learning Hands-on Workshop </h2>\n",
    "<h1 align='center'> Home Credit Default Risk Kaggle Competition </h1>\n",
    "\n",
    "<br>\n",
    "<center align=\"left\"> <h4>Presentened by:</h4> </center>\n",
    "<center align=\"left\"> <h4>Vanessa Feng, WeCloudData Academy</h4> </center>\n",
    "\n",
    "----------\n",
    "\n",
    "[Home Credit Default Risk Kaggle Competition](https://www.kaggle.com/c/home-credit-default-risk) Can you predict how capable each applicant is of repaying a loan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content:\n",
    "- [Problem analysis](#Problem-analysis)\n",
    "- [Methodologies](#Methodologies)\n",
    "    - [Building blocks of a Machine Learning algorithm](#Building-blocks-of-a-Machine-Learning-algorithm)\n",
    "    - [Attempt 1](#Attempt-1)\n",
    "        - [Data preparation](#Data-preparation)\n",
    "        - [Model training](#Model-training)\n",
    "        - [Model evaluation](#Model-evaluation)\n",
    "        - [Cross validation](#Cross-validation)\n",
    "        - [Model tuning](#Model-tuning)\n",
    "        - [Test data prediction](#Test-data-prediction)\n",
    "    - [Attempt 2](#Attempt-2)\n",
    "        - [Data preparation: multiple datasets](#Data-preparation:-multiple-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem analysis\n",
    "### Understand the problem\n",
    "Read the competition overview at https://www.kaggle.com/c/home-credit-default-risk#description.\n",
    "We are trying to predict whether each credit applicant is going to have payment difficulty or not.\n",
    "\n",
    "### Understand the data\n",
    "Read the dataset description at https://www.kaggle.com/c/home-credit-default-risk/data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a peak into the data files using shell command\n",
    "!head -n 10 data/installments_payments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a peak into the data files using pandas\n",
    "import pandas as pd\n",
    "filename = 'data/application_train.csv'\n",
    "df = pd.read_csv(filename)\n",
    "df.head(20) # print out the first 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes) # check the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the target distribution (raw count)\n",
    "df[['SK_ID_CURR', 'TARGET']].groupby('TARGET').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# understand the target distribution (ratio)\n",
    "df[['SK_ID_CURR', 'TARGET']].groupby('TARGET').count()/df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data files relationship\n",
    "<img src='dataset.png' width='100%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr></hr>\n",
    "\n",
    "# Methdologies\n",
    "\n",
    "## Building blocks of a Machine Learning algorithm\n",
    "<img src='training.png' width='80%'>\n",
    "\n",
    "<hr></hr>\n",
    "    \n",
    "### Phase 2: validation time\n",
    "\n",
    "<img src='validation.png' width='80%'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1\n",
    "Use one single dataset, basic feature extraction, and a single model to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use `application_{train|test}.csv` only\n",
    "# Take a look at the data fields in this file\n",
    "filename = 'data/HomeCredit_columns_description.csv'\n",
    "desc_df = pd.read_csv(filename, encoding = \"ISO-8859-1\")\n",
    "desc_df[desc_df['Table'] == 'application_{train|test}.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target distribution of the entire dataset\n",
    "def get_target_dist(df):\n",
    "    rows = df.shape[0]\n",
    "    target_dist_df = df[['SK_ID_CURR', 'TARGET']].groupby('TARGET').count()\n",
    "    target_dist_df['PERCENT'] = target_dist_df['SK_ID_CURR']*100/rows\n",
    "    return target_dist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the target distribution across the entire dataset\n",
    "train_df = pd.read_csv(filename)\n",
    "rows = train_df.shape[0] # total number of rows in the data\n",
    "print(f'total rows: {rows}')\n",
    "print(get_target_dist(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's just use a subset of this dataset by reading the first 10000 rows\n",
    "train_df = pd.read_csv(filename, nrows=10000)\n",
    "rows = train_df.shape[0] # total number of rows in the data\n",
    "print(f'total rows: {rows}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check the target distribution\n",
    "print(get_target_dist(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# better approach: randomly sample the entire dataset, not just take the first n rows\n",
    "filename = 'data/application_train.csv'\n",
    "train_df = pd.read_csv(filename)\n",
    "train_df = train_df.sample(n=10000)\n",
    "rows = train_df.shape[0] # total number of rows in the data\n",
    "print(f'total rows: {rows}') \n",
    "print(get_target_dist(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = train_df.columns[train_df.isnull().any()] # find out columns with any null value\n",
    "nan_cnt = train_df[nan_cols].isnull().sum()\n",
    "print(nan_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = [] # collect targets\n",
    "data = [] # data (all columns except the target)\n",
    "\n",
    "target_col = 'TARGET'\n",
    "features = list([x for x in train_df.columns if x != target_col])\n",
    "\n",
    "for row in train_df.to_dict('records'):\n",
    "    y.append(row[target_col])\n",
    "    data.append({k: row[k] for k in features})\n",
    "    \n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training-validation split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "data_train, data_val, y_train, y_val = train_test_split(data, y, train_size=0.8, stratify=y)\n",
    "print(f'data_train cnt: {len(data_train)}')\n",
    "print(f'data_val cnt: {len(data_val)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_y_dist(y):\n",
    "    target2cnt = defaultdict(int)\n",
    "    for yi in y:\n",
    "        target2cnt[yi] += 1\n",
    "    \n",
    "    print('target\\tcnt\\tratio')\n",
    "    for target in sorted(target2cnt):\n",
    "        cnt = target2cnt[target]\n",
    "        print(f'{target}\\t{cnt}\\t{cnt/len(y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('target distribution in training data')\n",
    "get_y_dist(y_train)\n",
    "\n",
    "print('\\ntarget distribution in validation data')\n",
    "get_y_dist(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# transform list of dictionary into numpy/scipy matrix\n",
    "vectorizer = DictVectorizer()\n",
    "X_train = vectorizer.fit_transform(data_train)\n",
    "print(f'after vectorization: {X_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect feature names\n",
    "for i, feature in enumerate(vectorizer.feature_names_):\n",
    "    print(f'{i}\\t{feature}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "# for each feature, fill in nan values with the mean value across all samples\n",
    "imputer = Imputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "\n",
    "# scaling data by columns so different features have roughly the same magnitude\n",
    "scaler = MaxAbsScaler()\n",
    "X_train = scaler.fit_transform(X_train.toarray())\n",
    "print(f'X_train data type: {type(X_train)}')\n",
    "print(f'X_train: {X_train.shape})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: use the same set of preprocessors (vectorizer, imputer, and scaler) to transform the validation/test data\n",
    "X_val = vectorizer.transform(data_val)\n",
    "X_val = imputer.transform(X_val)\n",
    "X_val = scaler.transform(X_val)\n",
    "print(f'X_val data type: {type(X_val)}')\n",
    "print(f'X_val: {X_val.shape})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "# fit model\n",
    "model = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "start = time.time()\n",
    "print(f'Fitting model on {X_train.shape[0]} samples...')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print('Finished model training in %.3f seconds.' % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_weights(y):\n",
    "    weights = []\n",
    "    for yi in y:\n",
    "        weights.append(10 if yi else 1)\n",
    "    return np.array(weights)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import time\n",
    "\n",
    "# fit model\n",
    "model = LogisticRegression()\n",
    "\n",
    "start = time.time()\n",
    "print(f'Fitting model on {X_train.shape[0]} samples...')\n",
    "model.fit(X_train, y_train, sample_weight=get_sample_weights(y_train))\n",
    "\n",
    "end = time.time()\n",
    "print('Finished model training in %.3f seconds.' % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation\n",
    "\n",
    "The competition uses the area under ROC curve for evaluation, see https://www.kaggle.com/c/home-credit-default-risk#evaluation.\n",
    "\n",
    "<img src='validation.png' width='100%'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform your trained model on test data to get predictions\n",
    "y_preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, y_pred in enumerate(y_preds):\n",
    "    y_true = y_val[i]\n",
    "    print(f'i\\ty_pred: {y_pred}, y_true: {y_true}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true=y_val, y_pred=y_preds, labels=[0, 1], target_names=['NO', 'YES']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_val, y_val):\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "    pos_idx = list(model.classes_).index(1)\n",
    "    # compute area under ROC\n",
    "    # we need probabilities to do this\n",
    "    print(X_val.shape, model.predict_proba(X_val).shape, pos_idx)\n",
    "    y_score = model.predict_proba(X_val)[:,pos_idx]\n",
    "    print(y_score.shape)\n",
    "    fpr, tpr, _ = roc_curve(y_val, y_score, pos_label=1)\n",
    "    roc_auc = roc_auc_score(y_val, y_score)\n",
    "#     print(f'auc: {auc}')\n",
    "    \n",
    "    return roc_auc, fpr, tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_val.shape)\n",
    "print(y_val.shape)\n",
    "roc_auc, fpr, tpr = evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "To get a more reliable performance evaluation of your model, you need to repeat the above random train-test split multiple times and average the performance across different splits. This is called **cross-validation**.\n",
    "\n",
    "The convention is to perform 5-fold or 10-fold cross-validation.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do we need more samples?**\n",
    "\n",
    "Previously, we just sampled 10000 samples from the entire `application_train.csv` dataset, and there's a chance we didn't have enough data to train the model.\n",
    "\n",
    "Offline practice: See how more training data will affect the overall performance.\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model tuning\n",
    "\n",
    "- **Hyper-parameter tuning**: pick a model and try different model hyper-parameters and pick the set of parameters with the best validation score\n",
    "  \n",
    "  **Example**: http://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py\n",
    "  \n",
    "- Try different models\n",
    "\n",
    "<hr></hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt2\n",
    "\n",
    "What if we use some of the other information provided?\n",
    "\n",
    "### Data preparation: multiple datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_app_filename = 'data/previous_application.csv'\n",
    "prev_app_df = pd.read_csv(prev_app_filename)\n",
    "prev_app_df.head(20) # print out the first 20 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/HomeCredit_columns_description.csv'\n",
    "desc_df = pd.read_csv(filename, encoding = \"ISO-8859-1\")\n",
    "desc_df[desc_df['Table'] == 'previous_application.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since it is a 1-N mapping between `SK_ID_CURR` and `SK_ID_PREV`, \n",
    "# we need to find a way to encode those variable number of corresponding \n",
    "# previous applications for a given current application.\n",
    "\n",
    "# one way to do this is by aggregating\n",
    "prev_agg = prev_app_df.groupby('SK_ID_CURR')\n",
    "prev_df = prev_agg.agg({'SK_ID_PREV': 'count', 'AMT_ANNUITY': 'sum'}).rename(columns={\n",
    "    'SK_ID_PREV': 'PREV_APPS', 'AMT_ANNUITY': 'PREV_AMT_ANNUITY'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_prev_df = train_df.fillna(value=train_df.mean()).join(prev_df, on='SK_ID_CURR', how='left')\n",
    "curr_prev_df[['PREV_APPS', 'PREV_AMT_ANNUITY']] = curr_prev_df[['PREV_APPS', 'PREV_AMT_ANNUITY']].fillna(value=0)\n",
    "print(curr_prev_df.shape[0])\n",
    "curr_prev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/bureau.csv'\n",
    "bureau_df = pd.read_csv(filename)\n",
    "active_bureau_df = bureau_df[bureau_df['CREDIT_ACTIVE']=='Active']\n",
    "active_bureau_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_bureau_agg = active_bureau_df.groupby('SK_ID_CURR')\n",
    "active_bureau_agg_df = active_bureau_agg.agg({'AMT_CREDIT_SUM_DEBT': 'sum', 'CNT_CREDIT_PROLONG': 'sum'})\n",
    "active_bureau_agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = curr_prev_df.join(active_bureau_agg_df, on='SK_ID_CURR', how='left')\n",
    "df[['AMT_CREDIT_SUM_DEBT', 'CNT_CREDIT_PROLONG']] = df[['AMT_CREDIT_SUM_DEBT', 'CNT_CREDIT_PROLONG']].fillna(value=0)\n",
    "print(df.shape[0])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
